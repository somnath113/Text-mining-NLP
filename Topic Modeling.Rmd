---
title: "Topic modeling with R"
author: "Somnath Mukherjee"
date: "June 12, 2019"
output: html_document
---

## Topic Modeling with LDA
Topic modeling is an unsupervised machine learning technique to automatically identify topics present in a text object and to derive hidden patterns exhibited by a text corpus. In topic modeling, documents are not assumed to belong to one topic or category, but simultaneously belong to several topics.    

The workhorse function for the topic model is LDA, which stands for Latent Dirichlet Allocation.    

### Install and Load Required Packages  

```{r,warning=FALSE,message=FALSE}
ipak <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
    sapply(pkg, require, character.only = TRUE)
}

# usage
packages <- c("knitr", "kableExtra", "tidyverse","psych", "PerformanceAnalytics",
              "topicmodels", "corrplot","SentimentAnalysis","tm","quanteda",
              "wordcloud")
ipak(packages)

```

### Data description  
We will now use a dataset that contains the lead paragraph of around 5,000 articles about the economy published in the New York Times between 1980 and 2014. As before, we will preprocess the text using the standard set of techniques.  

The number of topics in a topic model is somewhat arbitrary, so you need to play with the number of topics to see if you get anything more meaningful. We start here with 30 topics.  

```{r,message=FALSE,warning=FALSE}
nyt <- read.csv("nytimes.csv", stringsAsFactors = FALSE)
nytcorpus <- corpus(nyt$lead_paragraph)
nytdfm <- dfm(nytcorpus, remove=stopwords("english"), verbose=TRUE,
               remove_punct=TRUE, remove_numbers=TRUE)
cdfm <- dfm_trim(nytdfm, min_docfreq = 2)

# estimate LDA with K topics
K <- 30
lda <- LDA(cdfm, k = K, method = "Gibbs", 
                control = list(verbose=25L, seed = 123, burnin = 100, iter = 500))

```

We can use get_terms to the top n terms from the topic model, and get_topics to predict the top k topic for each document. This will help us interpret the results of the model.  

```{r}
terms <- get_terms(lda, 10)
terms[,1]
```
```{r}
topics <- get_topics(lda, 1)
head(topics)
```

List top 10 terms under each topic.  

```{r}
data.frame(terms(lda, 10))

```

Let's take a closer look at some of these topics. To help us interpret the output, we can look at the words associated with each topic and take a random sample of documents highly associated with each topic.  

```{r}
# Topic 11
paste(terms[,11], collapse=", ")

```

```{r}
sample(nyt$lead_paragraph[topics==11], 1)
```


```{r}
# add predicted topic to dataset
nyt$pred_topic <- topics
nyt$year <- substr(nyt$datetime, 1, 4) # extract year
# frequency table with articles about recession market, per year
tab <- table(nyt$year[nyt$pred_topic==11])
plot(tab)

```

LDA is a probabilistic model, which means that for each document, it actually computes a distribution over topics. In other words, each document is considered to be about a mixture of topics.  
This information is included in the matrix gamma in the LDA object.  


```{r}
# Topic 11
paste(terms[,11], collapse=", ")

```

So we can actually take the information in the matrix and aggregate it to compute the average probability that an article each year is about a particular topic. Let's now choose Topic 11, which appears to be related to the economic recession.    

```{r}
# add probability to df
nyt$prob_topic <- lda@gamma[,11]
# now aggregate at the year level
agg <- aggregate(nyt$prob_topic, by=list(year=nyt$year), FUN=mean)
# and plot it
plot(agg$year, agg$x, type="l", xlab="Year", ylab="Avg. prob. of article about topic 15",
     main="Estimated proportion of articles about the economic recession")

```

```{r}
topic <- 11
df <- data.frame(term = lda@terms, p = exp(lda@beta[topic,]))
head(df[order(-df$p),])
```

```{r}
wordcloud(words = df$term,
          freq = df$p,
          max.words = 20,
          random.order = FALSE,
          rot.per = 0.35,
          colors=brewer.pal(8, "Dark2"))
```

